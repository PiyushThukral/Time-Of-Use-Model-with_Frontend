{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dad6cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_folder = \"C:/Users/Piyush Thukral/Downloads\" #output_folder\n",
    "customer_data =  \"C:/Users/Piyush Thukral/Downloads/files_for_optariff_meet/1_individual_model/input_file_for_clustering_model1.xlsx\" #customer_data_file\n",
    "\n",
    "model_input_file = \"C:/Users/Piyush Thukral/Downloads/OPTARIFF_model_parameter_file_FORMAT (6).xlsx\" # model_input_file\n",
    "output_file_name = \"pt_test\"  #output_file_name_by_user\n",
    "output_file_path = f\"{output_folder}/{output_file_name}.xlsx\"\n",
    "\n",
    "cont_setting = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b749e828",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gurobipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#def run(customer_data_file, model_input_file, output_folder, output_file_name_str, tou_bins,total_time_blocks_modelled, cont_setting, output_file_name_by_user):\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#def run(customer_data_file, model_input_file, output_folder, output_file_name_str, tou_bins,total_time_blocks_modelled):\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgurobipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgurobipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GRB\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'gurobipy'"
     ]
    }
   ],
   "source": [
    "#def run(customer_data_file, model_input_file, output_folder, output_file_name_str, tou_bins,total_time_blocks_modelled, cont_setting, output_file_name_by_user):\n",
    "#def run(customer_data_file, model_input_file, output_folder, output_file_name_str, tou_bins,total_time_blocks_modelled):\n",
    "\n",
    "import gurobipy as gp\n",
    "import matplotlib.pyplot as plt\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "# Show all columns in display\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d3b650",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gurobipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#def run(customer_data_file, model_input_file, output_folder, output_file_name_str, tou_bins,total_time_blocks_modelled, cont_setting, output_file_name_by_user):\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#def run(customer_data_file, model_input_file, output_folder, output_file_name_str, tou_bins,total_time_blocks_modelled):\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgurobipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgurobipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GRB\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'gurobipy'"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "# # Define your output Excel file path\n",
    "# #output_file = f\"/output_file.xlsx\"  # Change this to your desired path\n",
    "# output_folder = output_folder\n",
    "# customer_data = customer_data_file\n",
    "# model_input_file = model_input_file\n",
    "# output_file_name = output_file_name_by_user\n",
    "# output_file_path = f\"{output_folder}/{output_file_name}.xlsx\"\n",
    "\n",
    "# print(f\"in model tou code and printing output file path: {output_file_path}\")\n",
    "\n",
    "\n",
    "# Read model parameters\n",
    "model_parameters =pd.read_excel(f\"{model_input_file}\", sheet_name= \"model_parameters\")  # Your file with cutoffs\n",
    "N = int(model_parameters[model_parameters['parameters'] == \"number_of_scenarios\"]['parameter_value'].values)\n",
    "#run_CVar_model = int(model_parameters[model_parameters['parameters'] == \"run_risk_weighted_Cvar\"]['parameter_value'].values)\n",
    "alpha = float(model_parameters[model_parameters['parameters'] == \"Cvar_alpha\"]['parameter_value'].values)\n",
    "\n",
    "cvar_auxiliary_lower_limit = int(model_parameters[model_parameters['parameters'] == \"cvar_auxiliary_lower_limit\"]['parameter_value'].values)\n",
    "cvar_auxiliary_upper_limit = int(model_parameters[model_parameters['parameters'] == \"cvar_auxiliary_upper_limit\"]['parameter_value'].values)\n",
    "var_lower_limit = float(model_parameters[model_parameters['parameters'] == \"var_lower_limit\"]['parameter_value'].values)\n",
    "var_upper_limit = float(model_parameters[model_parameters['parameters'] == \"var_upper_limit\"]['parameter_value'].values)\n",
    "\n",
    "min_power_consumer_after_load_shifting = float(model_parameters[model_parameters['parameters'] == \"min_power_consumer_after_load_shifting\"]['parameter_value'].values)\n",
    "consumption_col_prefix = (model_parameters.loc[model_parameters['parameters'] == \"consumption_col_prefix\"]['parameter_value'].values[0])\n",
    "\n",
    "# Read bins\n",
    "#tod_bins =pd.read_excel(f\"{model_input_file}\", sheet_name= \"ToD_for_tariff\")  # Your file with cutoffs\n",
    "\n",
    "#total_blocks = tod_bins['define_cut_off_periods'].max()\n",
    "#cutoffs = tod_bins['define_cut_off_periods'].values\n",
    "\n",
    "total_blocks = total_time_blocks_modelled\n",
    "cutoffs = tou_bins\n",
    "\n",
    "print(cutoffs)\n",
    "\n",
    "cutoffs.append(total_blocks)\n",
    "\n",
    "# Initialize start of first bin\n",
    "start = 1\n",
    "bins = []\n",
    "\n",
    "for cutoff in cutoffs:\n",
    "    bins.append((start, int(cutoff)))\n",
    "    start = int(cutoff) + 1\n",
    "\n",
    "# Number of bins\n",
    "T = len(bins)\n",
    "\n",
    "# Create Python ranges\n",
    "ranges = [range(s, e + 1) for s, e in bins]\n",
    "\n",
    "\n",
    "#tod_continuity_settings = int(model_parameters[model_parameters['parameters'] == \"tod_first_last_continuity_settings\"]['parameter_value'].values)\n",
    "\n",
    "# reading from run() inputs of the file\n",
    "tod_continuity_settings = cont_setting\n",
    "\n",
    "print(f\"Testing from Model code : Tod continuity setting----{tod_continuity_settings}...........\")\n",
    "\n",
    "def merge_first_last_if_needed(ranges, tod_continuity_settings):\n",
    "    if tod_continuity_settings == 1 and len(ranges) >= 2:\n",
    "        # Combine values from first and last ranges into one list\n",
    "        merged_values = list(ranges[0]) + list(ranges[-1])\n",
    "\n",
    "        # Create new list: merged bin + middle ranges (unmodified)\n",
    "        new_ranges = [merged_values] + ranges[1:-1]\n",
    "        return new_ranges\n",
    "    else:\n",
    "        return ranges\n",
    "\n",
    "\n",
    "merged_ranges = merge_first_last_if_needed(ranges, tod_continuity_settings)\n",
    "\n",
    "for i, r in enumerate(merged_ranges, 1):\n",
    "    print(f\"Bin {i}: {list(r)}\")\n",
    "\n",
    "T = len(merged_ranges)\n",
    "\n",
    "\n",
    "# Read TARIFF DATA\n",
    "tariff_data =pd.read_excel(f\"{model_input_file}\", sheet_name= \"existing_tariffs\")  # Your file with cutoffs\n",
    "\n",
    "# Stochasticity settings\n",
    "stochasticity =pd.read_excel(f\"{model_input_file}\", sheet_name= \"stochasticity_settings\")  # Your file with cutoffs\n",
    "\n",
    "std_dev_elasticity = float(stochasticity[stochasticity['stochasticity_variable'] == \"elasticity\"]['std_dev_value'].values)\n",
    "std_dev_market_prices = float(stochasticity[stochasticity['stochasticity_variable'] == \"marginal_price_of_procurement\"]['std_dev_value'].values)\n",
    "\n",
    "\n",
    "# Stochasticity settings\n",
    "\n",
    "demand_ramp_df =pd.read_excel(f\"{model_input_file}\", sheet_name= \"demand_ramp\")  # Your file with cutoffs\n",
    "\n",
    "#demand_ramp_lower_limit = float(demand_ramp_df[demand_ramp_df['demand_ramp'] == \"lower_limit\"]['ramp_value'].values)\n",
    "demand_ramp_upper_limit = float(demand_ramp_df[demand_ramp_df['demand_ramp'] == \"upper_limit\"]['ramp_value'].values)\n",
    "\n",
    "demand_ramp = demand_ramp_upper_limit\n",
    "\n",
    "\n",
    "scenarios = N\n",
    "W=N\n",
    "probability = np.ones(scenarios)*[1/scenarios]\n",
    "\n",
    "\n",
    "# Tariff limits\n",
    "tariff_limits =pd.read_excel(f\"{model_input_file}\", sheet_name= \"tariff_limits\")  # Your file with cutoffs\n",
    "\n",
    "lower_limit_to_change_allowed = float(tariff_limits[tariff_limits['parameter_name'] == \"lower_limit_to_change_allowed\"]['parameter_value'].values)\n",
    "upper_limit_to_change_allowed = float(tariff_limits[tariff_limits['parameter_name'] == \"upper_limit_to_change_allowed\"]['parameter_value'].values)\n",
    "lower_limit_tariff = float(tariff_limits[tariff_limits['parameter_name'] == \"lower_limit_tariff\"]['parameter_value'].values)\n",
    "upper_limit_to_tariff = float(tariff_limits[tariff_limits['parameter_name'] == \"upper_limit_to_tariff\"]['parameter_value'].values)\n",
    "\n",
    "#upper_limit_to_change_allowed\n",
    "\n",
    "\n",
    "env = gp.Env(empty=True)\n",
    "env.setParam(\"WLSACCESSID\", \"edcfd2fb-0fbd-4757-a9f9-d4ecf5906cba\")\n",
    "env.setParam(\"WLSSECRET\", \"c6f06522-b031-4619-8047-3861ae3d6880\")\n",
    "env.setParam(\"LICENSEID\", 2659587)\n",
    "env.start()\n",
    "\n",
    "model = gp.Model(\"test\", env=env)\n",
    "\n",
    "\n",
    "# Read bins\n",
    "consumer_load_norm_csv =pd.read_excel(f\"{customer_data}\")  # Your file with cutoffs\n",
    "#consumer_load_norm_csv =pd.read_excel(f\"{customer_data}\", sheet_name= \"consumer_data_demo\")  # Your file with cutoffs\n",
    "\n",
    "consumer_load_norm_csv['Consumer No'] = consumer_load_norm_csv['Consumer No'].astype(str)\n",
    "consumer_load_norm_csv = consumer_load_norm_csv.sort_values('Consumer No', ascending=True).reset_index(drop=True)\n",
    "\n",
    "### Define number of unique consumers\n",
    "J = consumer_load_norm_csv['Consumer No'].nunique()\n",
    "\n",
    "def generate_consumption_column_groups(merged_ranges, consumption_col_prefix):\n",
    "    column_groups = []\n",
    "    for r in merged_ranges:\n",
    "        if isinstance(r, range):\n",
    "            hours = list(r)\n",
    "        else:\n",
    "            hours = r  # assume it's already a list\n",
    "        group = [f\"{consumption_col_prefix}{h}\" for h in hours]\n",
    "        column_groups.append(group)\n",
    "    return column_groups\n",
    "\n",
    "column_groups = generate_consumption_column_groups(merged_ranges, consumption_col_prefix)\n",
    "\n",
    "for i, group in enumerate(column_groups, 1):\n",
    "    print(f\"Bin {i}: {group}\")\n",
    "\n",
    "def add_total_period_columns(df, column_groups, T):\n",
    "    total_group_columns = [f\"Total_in_period_{h}\" for h in range(1, T+1)]\n",
    "    average_group_columns = [f\"Average_in_period_{h}\" for h in range(1, T+1)]\n",
    "\n",
    "    for i, cols in enumerate(column_groups, start=1):\n",
    "        df[f\"Total_in_period_{i}\"] = df[cols].sum(axis=1)\n",
    "        df[f\"Average_in_period_{i}\"] = df[f\"Total_in_period_{i}\"] / len(cols)\n",
    "\n",
    "    return df, total_group_columns, average_group_columns\n",
    "\n",
    "# Usage: unpack all three returned values\n",
    "df, total_group_columns, average_group_columns = add_total_period_columns(consumer_load_norm_csv, column_groups, T)\n",
    "\n",
    "monthly_consumption = df.groupby(\"Consumer No\")[total_group_columns].sum().reset_index()\n",
    "\n",
    "monthly_consumption['monthly_consumption'] = monthly_consumption[total_group_columns].sum(axis=1)\n",
    "\n",
    "df[\"monthly_consumption\"] = df[\"Consumer No\"].map(monthly_consumption.set_index(\"Consumer No\")[\"monthly_consumption\"])\n",
    "\n",
    "# Group by 'consumer_no' and calculate mean for average columns\n",
    "grouped_df = df.groupby(\"Consumer No\")[average_group_columns].mean().reset_index()\n",
    "\n",
    "consumer_load_norm = grouped_df.iloc[:, -T:].values\n",
    "\n",
    "consumer_load_time_block_order =  grouped_df.drop([\"Consumer No\"], axis=1).columns\n",
    "\n",
    "L_C =[len(merged_ranges[timeblock]) for timeblock in range(T)]\n",
    "\n",
    "\n",
    "# Define bins and labels for total monthly consumption\n",
    "bins = [0, 120, 240, float('inf')]\n",
    "labels = ['0-120', '120-240', '240+']\n",
    "\n",
    "# Create a new column for the bins\n",
    "if ('consumption_bin' in df.columns) == False:\n",
    "    df['consumption_bin'] = pd.cut(\n",
    "        df['monthly_consumption'],\n",
    "        bins=bins,\n",
    "        labels=labels,\n",
    "        right=False\n",
    "    )\n",
    "\n",
    "\n",
    "# Read bins\n",
    "# peak_price_hours =pd.read_excel(f\"{model_input_file}\", sheet_name= \"peak_price_hours\")  # Your file with cutoffs\n",
    "\n",
    "# total_blocks = peak_price_hours['Peak_Hour'].max()\n",
    "# cutoffs = peak_price_hours['Peak_Hour'].values\n",
    "\n",
    "# # Initialize start of first bin\n",
    "# start = peak_price_hours['Peak_Hour'].min()\n",
    "# bins = []\n",
    "\n",
    "# for cutoff in cutoffs:\n",
    "#     bins.append((start, int(cutoff)))\n",
    "#     start = int(cutoff) + 1\n",
    "\n",
    "# # Create Python ranges\n",
    "# peak_range = [range(s, e + 1) for s, e in bins]\n",
    "\n",
    "elasticity_estimate =pd.read_excel(f\"{model_input_file}\", sheet_name= \"elasticity_settings\")  # Your file with cutoffs\n",
    "\n",
    "sp_unit_norm_cost_org = pd.read_excel(f\"{model_input_file}\", sheet_name=\"procurement_costs\")\n",
    "\n",
    "\n",
    "sp_unit_norm_cost_org = sp_unit_norm_cost_org[[\"marginal_price_of_procurement\"]].values\n",
    "\n",
    "sp_unit_norm_cost_org = sp_unit_norm_cost_org.flatten()\n",
    "\n",
    "sp_unit_norm_cost = np.zeros((scenarios, len(sp_unit_norm_cost_org)))\n",
    "\n",
    "sp_unit_norm_cost[0, :] = sp_unit_norm_cost_org/1000\n",
    "\n",
    "for scenario in range(1, scenarios):\n",
    "    std_dev = abs(np.random.normal(0, std_dev_market_prices))  # Ensure std_dev is non-negative\n",
    "    sp_unit_norm_cost[scenario, :] = sp_unit_norm_cost[0, :] + np.random.normal(0, std_dev, size=sp_unit_norm_cost_org.shape)\n",
    "\n",
    "\n",
    "sp_unit_norm_cost = np.where(sp_unit_norm_cost < 0, 0.01, sp_unit_norm_cost)\n",
    "sp_unit_norm_cost = np.where(sp_unit_norm_cost > 10, 10, sp_unit_norm_cost)\n",
    "\n",
    "\n",
    "R = sp_unit_norm_cost.shape[1]\n",
    "\n",
    "\n",
    "def create_membership_matrix(merged_ranges, sp_total_blocks, column_heads):\n",
    "    \"\"\"\n",
    "    Create a binary matrix of shape (T, R),\n",
    "    where T = number of merged ranges,\n",
    "    R = total number of time blocks,\n",
    "    matrix[t, r] = 1 if r in merged_ranges[t], else 0.\n",
    "\n",
    "    Args:\n",
    "        merged_ranges: list of range objects or lists defining each bin.\n",
    "        total_blocks: int, total number of time blocks (R).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: binary matrix (T x R)\n",
    "    \"\"\"\n",
    "\n",
    "    total_columns = 0\n",
    "    for group in column_heads:\n",
    "        total_columns += len(group)\n",
    "\n",
    "    T = len(merged_ranges)\n",
    "    R = total_columns\n",
    "    matrix = np.zeros((T, R), dtype=int)\n",
    "\n",
    "    for t, time_range in enumerate(merged_ranges):\n",
    "        for r in range(R):\n",
    "            # Time blocks are often 1-based, adjust if your ranges and indexing differ\n",
    "            # Here assuming time blocks start at 1, and matrix columns index at 0\n",
    "            time_block = r + 1\n",
    "            if time_block in time_range:\n",
    "                matrix[t, r] = 1\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "membership_matrix = create_membership_matrix(merged_ranges, total_blocks,column_groups)\n",
    "\n",
    "\n",
    "\n",
    "## DEFINE THE VARIABLES\n",
    "\n",
    "u_auxiliary = model.addVars(scenarios, vtype=GRB.CONTINUOUS, lb = cvar_auxiliary_lower_limit, ub = cvar_auxiliary_upper_limit, name=\"u_auxiliary\")\n",
    "delta_lambda = model.addVars(J, T, lb = lower_limit_to_change_allowed,  ub = upper_limit_to_change_allowed,  vtype=GRB.CONTINUOUS, name=\"delta_lambda\")\n",
    "value_at_risk = model.addVar(vtype=GRB.CONTINUOUS, lb= var_lower_limit,ub = var_upper_limit, name=\"value_at_risk\")\n",
    "\n",
    "\n",
    "# DEFINE THE PARAMETERS\n",
    "\n",
    "lambda_C = np.ones((J,T))  # energy price in respective time slots\n",
    "elasticity = np.ones((J,T,W))  #Elasticity of the consumer j in period t in scenario w\n",
    "lambda_P = sp_unit_norm_cost.T # pool price for period R and scenario w\n",
    "\n",
    "\n",
    "elasticity = consumer_load_norm_csv[['Consumer No', 'Category']].drop_duplicates()\n",
    "\n",
    "\n",
    "# Clean the Category column to be lowercase and remove spaces\n",
    "elasticity['Category'] = elasticity['Category'].str.lower().str.replace(' ', '')\n",
    "elasticity_estimate['category_name'] = elasticity_estimate['category_name'].str.lower().str.replace(' ', '')\n",
    "\n",
    "# Create mapping dictionaries\n",
    "elasticity_estimate_map = elasticity_estimate.set_index('category_name')['category_elasticity'].to_dict()\n",
    "\n",
    "# Apply mapping\n",
    "elasticity['elasticity'] = elasticity['Category'].map(elasticity_estimate_map)\n",
    "\n",
    "elasticity_matrix = np.tile(elasticity['elasticity'].values[:, np.newaxis, np.newaxis], (1, T, W))\n",
    "elasticity_matrix.shape\n",
    "\n",
    "lambda_C_assam = df[['Consumer No', 'Category',\"consumption_bin\"]].drop_duplicates()\n",
    "\n",
    "\n",
    "lambda_C_assam = lambda_C_assam[[\"Category\", \"consumption_bin\"]]\n",
    "\n",
    "# Clean the Category column to be lowercase and remove spaces\n",
    "lambda_C_assam['Category'] = lambda_C_assam['Category'].str.lower().str.replace(' ', '')\n",
    "tariff_data['category_name'] = tariff_data['category_name'].str.lower().str.replace(' ', '')\n",
    "\n",
    "dom_a_bin_tariff = lambda_C_assam[lambda_C_assam['Category'] == \"doma\"]\n",
    "\n",
    "dom_a_bin_tariff.shape\n",
    "\n",
    "# Filter for DOM A rows in tariff_data\n",
    "dom_a_mask = lambda_C_assam['Category'] == 'doma'\n",
    "\n",
    "if dom_a_bin_tariff.shape[0] != 0:\n",
    "    # Create a mapping from consumption_bin to average_energy_tariff for DOM A\n",
    "    dom_a_bin_tariff_map = dom_a_bin_tariff.set_index('consumption_bin')['average_energy_tariff'].to_dict()\n",
    "    # Update the 'energy_charges' column for DOM A rows using the mapping\n",
    "    lambda_C_assam.loc[dom_a_mask, 'energy_charges'] = lambda_C_assam.loc[dom_a_mask, 'consumption_bin'].map(dom_a_bin_tariff_map)\n",
    "    # Display the updated rows for verification\n",
    "\n",
    "\n",
    "# Create mapping dictionaries\n",
    "fixed_charge_map = tariff_data.set_index('category_name')['fixed_charges'].to_dict()\n",
    "energy_charge_map = tariff_data.set_index('category_name')['energy_charges'].to_dict()\n",
    "\n",
    "# Apply mapping\n",
    "lambda_C_assam['Revised_Fixed_Charges'] = lambda_C_assam['Category'].map(fixed_charge_map)\n",
    "lambda_C_assam['energy_charges'] = lambda_C_assam['Category'].map(energy_charge_map)\n",
    "\n",
    "\n",
    "\n",
    "lambda_C_array = np.tile(lambda_C_assam['energy_charges'].values, (T, 1)).T\n",
    "lambda_C = lambda_C_array\n",
    "\n",
    "\n",
    "# Step 2: Generate vector v from normal distribution\n",
    "v = np.random.normal(loc=0.0, scale=std_dev_elasticity, size=N)\n",
    "\n",
    "# Step 3: Create a 3D array of shape (J, T, N)\n",
    "# Step 4: Broadcast v to shape (J, T, N)\n",
    "result = np.tile(v, (J, T, 1))  # shape will be (J, T, N)\n",
    "\n",
    "\n",
    "## Create Stochastic Elasticity\n",
    "elasticity = elasticity_matrix + result\n",
    "\n",
    "\n",
    "consumer_category = (\n",
    "    consumer_load_norm_csv['Consumer No'].unique()\n",
    ")\n",
    "\n",
    "\n",
    "consumer_load = consumer_load_norm\n",
    "\n",
    "# # Plotting\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# for consumer in range(consumer_load_norm.shape[0]):\n",
    "#     plt.plot(consumer_load_norm[consumer, :], label=f\"Consumer {consumer_category[consumer]}\", linewidth=2, linestyle='--')\n",
    "\n",
    "# plt.xlabel(\"Time Blocks\")\n",
    "# plt.xticks(range(T))\n",
    "# plt.ylabel(\"Units consumed (kWh)\")\n",
    "# plt.title(\"Consumer Load Profiles\")\n",
    "# plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3)  # Legend at the bottom\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(14, 6))\n",
    "# for scenario in range(scenarios):\n",
    "#     plt.plot(sp_unit_norm_cost[scenario,:], linewidth=2, linestyle =\"--\")\n",
    "# #plt.plot(fc_unit_cost, label='Forward Contract Price', linestyle= '--', color= 'black')\n",
    "# plt.xlabel(\"Time Blocks\")\n",
    "# plt.ylabel(\"Unit Cost (Rs/MWh)\")\n",
    "# plt.title(\"Unit Norm Cost Profiles with High Price Variability in Non-Solar Hours\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "run_CVar_model =1\n",
    "if run_CVar_model == 1:\n",
    "    # Equation_9\n",
    "    model_objective = value_at_risk  - ( 1/ (1- alpha))*gp.quicksum( probability[scenario]*u_auxiliary[scenario] for scenario in range(scenarios))\n",
    "\n",
    "    # Equation_15\n",
    "\n",
    "    # RHS : First term\n",
    "    # value_at_risk\n",
    "\n",
    "    # RHS : Second term\n",
    "    # gp.quicksum( consumer_load[consumer,timeblock]*delta_lambda[consumer,timeblock] for consumer in range(J) for timeblock in range(T) )\n",
    "\n",
    "    # RHS : Third term\n",
    "    # gp.quicksum( elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*delta_lambda[consumer,timeblock] for consumer in range(J) for timeblock in range(T) )\n",
    "\n",
    "    # RHS : Fourth term\n",
    "    # gp.quicksum( (1/(lambda_C[consumer,timeblock]))*(elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*delta_lambda[consumer,timeblock]*delta_lambda[consumer,timeblock]) for consumer in range(J) for timeblock in range(T) )\n",
    "\n",
    "    # RHS : Fifth term\n",
    "    # gp.quicksum( (1/(lambda_C[consumer,timeblock]))*(elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*delta_lambda[consumer,timeblock]*lambda_P[timeblock,consumer]) for consumer in range(J) for timeblock in range(T) )\n",
    "\n",
    "    model.addConstrs( ( u_auxiliary[scenario]\n",
    "                    >=\n",
    "                    value_at_risk\n",
    "                    - gp.quicksum( consumer_load[consumer,timeblock]*L_C[timeblock]*delta_lambda[consumer,timeblock] for consumer in range(J) for timeblock in range(T) )\n",
    "                    + gp.quicksum( elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*L_C[timeblock]*delta_lambda[consumer,timeblock] for consumer in range(J) for timeblock in range(T) )\n",
    "                    + gp.quicksum( (1/(lambda_C[consumer,timeblock]))*(elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*L_C[timeblock]*delta_lambda[consumer,timeblock]*delta_lambda[consumer,timeblock]) for consumer in range(J) for timeblock in range(T) )\n",
    "                    - gp.quicksum( (1/(lambda_C[consumer,timeblock]))*(elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*membership_matrix[timeblock,sp_timeblock]*delta_lambda[consumer,timeblock]*lambda_P[sp_timeblock,scenario]) for consumer in range(J) for sp_timeblock in range(R) for timeblock in range(T) )\n",
    "                    for scenario in range(scenarios) )\n",
    "                    , name= \"Equation_15_w\" )\n",
    "\n",
    "    model.update()\n",
    "\n",
    "    model.setObjective(model_objective, GRB.MAXIMIZE)\n",
    "\n",
    "else:\n",
    "    # Calculate the change in profit\n",
    "\n",
    "    # term_1 = gp.quicksum(probability[scenario]*( 1 - elasticity[consumer,timeblock,scenario])*consumer_load[consumer,timeblock]*L_C[timeblock]*delta_lambda[consumer,timeblock] for scenario in range(scenarios) for timeblock in range(T) for consumer in range(J))\n",
    "    # term_2 = gp.quicksum( (1/lambda_C[consumer,timeblock])*probability[scenario]*elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*L_C[timeblock]*delta_lambda[consumer,timeblock]*delta_lambda[consumer,timeblock] for scenario in range(scenarios) for timeblock in range(T) for consumer in range(J) )\n",
    "    # term_3 = gp.quicksum( (1/lambda_C[consumer,timeblock])*probability[scenario]*consumer_load[consumer,timeblock]*L_C[timeblock]*sp_unit_norm_cost[scenario,timeblock]*delta_lambda[consumer,timeblock] for scenario in range(scenarios) for timeblock in range(T) for consumer in range(J) )\n",
    "\n",
    "    # expected_profit = -(term_1 - term_2 + term_3)\n",
    "\n",
    "    term_1 = gp.quicksum(probability[scenario]*( 1 - elasticity[consumer,timeblock,scenario])*consumer_load[consumer,timeblock]*L_C[timeblock]*delta_lambda[consumer,timeblock] for scenario in range(scenarios) for timeblock in range(T) for consumer in range(J))\n",
    "    term_2 = gp.quicksum( (1/lambda_C[consumer,timeblock])*probability[scenario]*elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*L_C[timeblock]*delta_lambda[consumer,timeblock]*delta_lambda[consumer,timeblock] for scenario in range(scenarios) for timeblock in range(T) for consumer in range(J) )\n",
    "    term_3 = gp.quicksum( (1/lambda_C[consumer,timeblock])*probability[scenario]*elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*sp_unit_norm_cost[scenario,timeblock]*membership_matrix[timeblock,sp_timeblock]*delta_lambda[consumer,timeblock] for scenario in range(scenarios) for sp_timeblock in range(R) for timeblock in range(T) for consumer in range(J) )\n",
    "\n",
    "    expected_profit = (term_1 - term_2 + term_3)\n",
    "\n",
    "    model.setObjective(expected_profit, GRB.MAXIMIZE)\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "# Constraint to add lower limit on expected change in profit\n",
    "\n",
    "\n",
    "term_1 = gp.quicksum(probability[scenario]*( 1 - elasticity[consumer,timeblock,scenario])*consumer_load[consumer,timeblock]*L_C[timeblock]*delta_lambda[consumer,timeblock] for scenario in range(scenarios) for timeblock in range(T) for consumer in range(J))\n",
    "term_2 = gp.quicksum( (1/lambda_C[consumer,timeblock])*probability[scenario]*elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*L_C[timeblock]*delta_lambda[consumer,timeblock]*delta_lambda[consumer,timeblock] for scenario in range(scenarios) for timeblock in range(T) for consumer in range(J) )\n",
    "term_3 = gp.quicksum( (1/lambda_C[consumer,timeblock])*probability[scenario]*elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*sp_unit_norm_cost[scenario,timeblock]*membership_matrix[timeblock,sp_timeblock]*delta_lambda[consumer,timeblock] for scenario in range(scenarios) for sp_timeblock in range(R) for timeblock in range(T) for consumer in range(J) )\n",
    "\n",
    "expected_profit = term_1 - term_2 + term_3\n",
    "\n",
    "model.addConstr( expected_profit >= 0)\n",
    "\n",
    "model.update()\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "# Equation_10\n",
    "# Energy consumed by each consumer in a day cannot be modified\n",
    "# Only load shifting within time periods in a day is allowed\n",
    "\n",
    "# NOTE. Haven't inserted any L_t_C term in this equation yet.\n",
    "# ---> UPDATE: ADDED L_C now\n",
    "\n",
    "# P_t_C = consumer_load[consumer,timeblock]\n",
    "\n",
    "model.addConstrs( ( - gp.quicksum( (1/(lambda_C[consumer,timeblock]))*(elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*L_C[timeblock]*delta_lambda[consumer,timeblock]) for timeblock in range(T) )\n",
    "                    ==\n",
    "                    0 for consumer in range(J) for scenario in range(scenarios) )\n",
    "                    , name = \"Equation_10_j_w\" )\n",
    "\n",
    "model.update()\n",
    "\n",
    "\n",
    "# Equation_11\n",
    "# Payments of each consumer cannot increase\n",
    "\n",
    "# NOTE. Haven't inserted any L_t_C term in this equation yet.\n",
    "# --.>>> Now, *L_C[timeblock] modification made\n",
    "\n",
    "# RHS\n",
    "# gp.quicksum( consumer_load[consumer,timeblock]*lambda_C[consumer,timeblock] for timeblock in range(T) )\n",
    "\n",
    "# LHS : Second term\n",
    "# gp.quicksum( consumer_load[consumer,timeblock]*( lambda_C[consumer,timeblock] + delta_lambda[consumer,timeblock]) for timeblock in range(T) )\n",
    "\n",
    "# LHS : First term\n",
    "# gp.quicksum( (1/(lambda_C[consumer,timeblock]))*(elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*delta_lambda[consumer,timeblock])*( lambda_C[consumer,timeblock] + delta_lambda[consumer,timeblock]) for timeblock in range(T) )\n",
    "\n",
    "model.addConstrs( (gp.quicksum( (1/(lambda_C[consumer,timeblock]))*L_C[timeblock]*(elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*delta_lambda[consumer,timeblock])*( lambda_C[consumer,timeblock] + delta_lambda[consumer,timeblock]) for timeblock in range(T) )\n",
    "                    - gp.quicksum( consumer_load[consumer,timeblock]*L_C[timeblock]*( lambda_C[consumer,timeblock] + delta_lambda[consumer,timeblock]) for timeblock in range(T) )\n",
    "                    -  gp.quicksum( consumer_load[consumer,timeblock]*L_C[timeblock]*lambda_C[consumer,timeblock] for timeblock in range(T) )\n",
    "                    <=\n",
    "                    0\n",
    "                    for consumer in range(J) for scenario in range(scenarios) ),\n",
    "                    name = \"Equation_11_j_w\" )\n",
    "\n",
    "model.update()\n",
    "\n",
    "\n",
    "# Equation_12\n",
    "\n",
    "# Tariffs after modification cannot be negative\n",
    "\n",
    "model.addConstrs( ( lambda_C[consumer,timeblock] + delta_lambda[consumer,timeblock]\n",
    "                    >=\n",
    "                    lower_limit_tariff\n",
    "                    for consumer in range(J) for timeblock in range(T)\n",
    "                    ),\n",
    "                    name = \"Equation_12_j_w\" )\n",
    "\n",
    "model.update()\n",
    "\n",
    "# Additional constraint - UPPER LIMIT TO OPTIMIZED TARIFF\n",
    "\n",
    "model.addConstrs( ( lambda_C[consumer,timeblock] + delta_lambda[consumer,timeblock]\n",
    "                    <=\n",
    "                    upper_limit_to_tariff\n",
    "                    for consumer in range(J) for timeblock in range(T)\n",
    "                    ),\n",
    "                    name = \"Equation_upper_tariff_limit_j_w\" )\n",
    "\n",
    "model.update()\n",
    "\n",
    "\n",
    "# Equation_13\n",
    "\n",
    "# Power consumer by each consumer after load-shifting cannot be negative\n",
    "\n",
    "\n",
    "model.addConstrs( ( consumer_load[consumer,timeblock]\n",
    "                    -\n",
    "                    (1/(lambda_C[consumer,timeblock]))*(elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*delta_lambda[consumer,timeblock])\n",
    "                    >=\n",
    "                    min_power_consumer_after_load_shifting\n",
    "                    for consumer in range(J)\n",
    "                    for timeblock in range(T)\n",
    "                    for scenario in range(scenarios)\n",
    "                    )\n",
    "                    ,name = \"Equation_13_j_t_w\" )\n",
    "\n",
    "model.update()\n",
    "\n",
    "\n",
    "# Equation_14\n",
    "\n",
    "# Demand ramping constraint - Lower Limit\n",
    "\n",
    "model.addConstrs( ( - demand_ramp*consumer_load[consumer,timeblock]\n",
    "                    <=\n",
    "                    - (1/(lambda_C[consumer,timeblock]))*(elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*delta_lambda[consumer,timeblock])\n",
    "                    for consumer in range(J)\n",
    "                    for timeblock in range(T)\n",
    "                    for scenario in range(scenarios)\n",
    "                    )\n",
    "                    ,name = \"Equation_14_lower_limit_j_t_w\" )\n",
    "\n",
    "# Demand ramping constraint - Upper Limit\n",
    "\n",
    "model.addConstrs( ( - (1/(lambda_C[consumer,timeblock]))*(elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*delta_lambda[consumer,timeblock])\n",
    "                    <=\n",
    "                    demand_ramp*consumer_load[consumer,timeblock]\n",
    "                    for consumer in range(J)\n",
    "                    for timeblock in range(T)\n",
    "                    for scenario in range(scenarios)\n",
    "                    )\n",
    "                    ,name = \"Equation_14_upper_limit_j_t_w\" )\n",
    "\n",
    "model.update()\n",
    "\n",
    "\n",
    "model.printStats()\n",
    "\n",
    "\n",
    "model.setParam(\"LogFile\", \"SM_model_t2.log\")\n",
    "model.setParam('PreDual', 1)\n",
    "model.setParam('Seed', 42)                # Set a fixed random seed\n",
    "model.setParam('Threads', 1)\n",
    "\n",
    "\n",
    "#Include any .log file with the solver output\n",
    "model.write(\"SM_model_t2.mps\")\n",
    "\n",
    "model.optimize()\n",
    "\n",
    "\n",
    "# Calculate the change in profit\n",
    "\n",
    "term_1 = gp.quicksum(probability[scenario]*( 1 - elasticity[consumer,timeblock,scenario])*consumer_load[consumer,timeblock]*L_C[timeblock]*delta_lambda[consumer,timeblock] for scenario in range(scenarios) for timeblock in range(T) for consumer in range(J)).getValue()\n",
    "\n",
    "term_2 = gp.quicksum( (1/lambda_C[consumer,timeblock])*probability[scenario]*elasticity[consumer,timeblock,scenario]*consumer_load[consumer,timeblock]*L_C[timeblock]*delta_lambda[consumer,timeblock]*delta_lambda[consumer,timeblock] for scenario in range(scenarios) for timeblock in range(T) for consumer in range(J) ).getValue()\n",
    "\n",
    "term_3 = gp.quicksum( (1/lambda_C[consumer,timeblock])*probability[scenario]*consumer_load[consumer,timeblock]*L_C[timeblock]*sp_unit_norm_cost[scenario,timeblock]*delta_lambda[consumer,timeblock] for scenario in range(scenarios) for timeblock in range(T) for consumer in range(J) ).getValue()\n",
    "\n",
    "change_in_profit = term_1 - term_2 + term_3\n",
    "\n",
    "\n",
    "#consumer_load_time_block_order\n",
    "\n",
    "consumer_number_series = pd.Series(consumer_load_norm_csv['Consumer No'].unique())\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "# Initialize an empty list to hold results\n",
    "profit_changes = []\n",
    "\n",
    "for consumer in range(len(consumer_number_series)):\n",
    "    try:\n",
    "        # Compute the three terms per consumer\n",
    "        term_1 = gp.quicksum(\n",
    "            probability[scenario] * (1 - elasticity[consumer, timeblock, scenario]) *\n",
    "            consumer_load[consumer, timeblock] * L_C[timeblock] * delta_lambda[consumer, timeblock]\n",
    "            for scenario in range(scenarios) for timeblock in range(T)\n",
    "        ).getValue()\n",
    "\n",
    "        term_2 = gp.quicksum(\n",
    "            (1 / lambda_C[consumer, timeblock]) * probability[scenario] *\n",
    "            elasticity[consumer, timeblock, scenario] * consumer_load[consumer, timeblock] *\n",
    "            L_C[timeblock] * delta_lambda[consumer, timeblock] ** 2\n",
    "            for scenario in range(scenarios) for timeblock in range(T)\n",
    "        ).getValue()\n",
    "\n",
    "        term_3 = gp.quicksum(\n",
    "            (1 / lambda_C[consumer, timeblock]) * probability[scenario] *\n",
    "            consumer_load[consumer, timeblock] * L_C[timeblock] *\n",
    "            sp_unit_norm_cost[scenario, timeblock] * delta_lambda[consumer, timeblock]\n",
    "            for scenario in range(scenarios) for timeblock in range(T)\n",
    "        ).getValue()\n",
    "\n",
    "        change_in_profit = (term_1 - term_2 + term_3)*30\n",
    "\n",
    "        profit_changes.append({\"Consumer_No\": consumer_number_series[consumer], \"Change_in_Profit\": change_in_profit})\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle any exceptions, e.g., key errors or divide-by-zero issues\n",
    "        profit_changes.append({\"Consumer_No\": consumer_number_series[consumer], \"Change_in_Profit\": None, \"Error\": str(e)})\n",
    "\n",
    "# Create DataFrame\n",
    "df_change_in_profit = pd.DataFrame(profit_changes)\n",
    "\n",
    "# Optionally drop rows with errors\n",
    "df_change_in_profit = df_change_in_profit[df_change_in_profit[\"Change_in_Profit\"].notnull()]\n",
    "\n",
    "\n",
    "# Insert a new row \"TOTAL\" that sums the \"Change_in_Profit\" column\n",
    "total_profit = df_change_in_profit[\"Change_in_Profit\"].sum()\n",
    "#df_change_in_profit.loc[\"TOTAL\"] = {\"Consumer_No\": \"TOTAL\", \"Change_in_Profit\": total_profit}\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract tou_timeblock_tariff values into a DataFrame with dimensions (J x T)\n",
    "# Create the DataFrame\n",
    "delta_lambda_df = pd.DataFrame(\n",
    "    #[[ round(delta_lambda[j, t].X/(L_C[t]),5) for t in range(T)] for j in range(J)],  ### Should this be divided by per period hour\n",
    "    [[ round(delta_lambda[j, t].X,5) for t in range(T)] for j in range(J)],\n",
    "    columns=[f\"Period_{t}\" for t in range(T)]\n",
    ")\n",
    "\n",
    "delta_lambda_df.insert(0, 'Consumer No', consumer_number_series)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Extract tou_timeblock_tariff values into a DataFrame with dimensions (J x T)\n",
    "# Create the DataFrame\n",
    "modified_lambda_df = pd.DataFrame(\n",
    "    [[round(delta_lambda[j, t].X, 5) + lambda_C[j, t] for t in range(T)] for j in range(J)],\n",
    "    columns=[f\"Period_{t}\" for t in range(T)]\n",
    ")\n",
    "\n",
    "modified_lambda_df.insert(0, 'Consumer No', consumer_number_series)\n",
    "\n",
    "modified_lambda_df['Consumer No'] = modified_lambda_df['Consumer No'].astype(str).replace(\" \", \"\")\n",
    "\n",
    "\n",
    "\n",
    "# Extract fc_purchase values into a DataFrame\n",
    "value_at_risk_df = pd.DataFrame(\n",
    "    [round(value_at_risk.X,10)],\n",
    "    columns=[f\"Risk_premium\"],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Extract fc_purchase values into a DataFrame\n",
    "u_auxiliary_df = pd.DataFrame(\n",
    "    [round(u_auxiliary[scenario].X,2) for scenario in range(scenarios)],\n",
    "    columns=[f\"u_auxiliary\"],\n",
    "    index=[f\"Scenario_{scenario}\" for scenario in range(scenarios)]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daaef66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d8515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502223b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_demand_df = df\n",
    "\n",
    "\n",
    "consumer_demand_df['consumer_category_full'] = (\n",
    "    consumer_demand_df['Category'].astype(str).str.upper().str.replace(\" \", \"\")\n",
    "    + '|' +\n",
    "    #consumer_demand_df['Sanctioned_Load_Group'].astype(str) + '|' +\n",
    "    'Monthly_consumption_' + consumer_demand_df['consumption_bin'].astype(str)\n",
    "    #+ '|' +\n",
    "    #'Cluster_' + consumer_demand_df['KMeans_Cluster'].astype('Int64').astype(str)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Merge on \"Consumer No\" to bring Period_1 to Period_T columns\n",
    "\n",
    "if \"Period_0\" not in consumer_demand_df.columns:\n",
    "\n",
    "    consumer_demand_df['Consumer No'] = consumer_demand_df['Consumer No'].astype(str).replace(\" \", \"\")\n",
    "\n",
    "    consumer_demand_df = consumer_demand_df.merge(\n",
    "        modified_lambda_df[[\"Consumer No\"] + [f\"Period_{i}\" for i in range(T)]],\n",
    "        on=\"Consumer No\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "\n",
    "consumption_df = consumer_demand_df\n",
    "\n",
    "# Step 1: Normalize the Category column in consumption_df\n",
    "consumption_df['Category_normalized'] = (\n",
    "    consumption_df['Category'].str.lower().str.replace(\" \", \"\", regex=False)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Normalize Category in lambda_C_assam\n",
    "lambda_C_assam['Category_normalized'] = (\n",
    "    lambda_C_assam['Category'].str.lower().str.replace(\" \", \"\", regex=False)\n",
    ")\n",
    "\n",
    "# Step 2: Create the maps\n",
    "energy_charge_map = dict(\n",
    "    zip(lambda_C_assam['Category_normalized'], lambda_C_assam['energy_charges'])\n",
    ")\n",
    "\n",
    "fixed_charge_map = dict(\n",
    "    zip(lambda_C_assam['Category_normalized'], lambda_C_assam['Revised_Fixed_Charges'])\n",
    ")\n",
    "\n",
    "\n",
    "# Apply maps\n",
    "consumption_df['energy_charge'] = consumption_df['Category_normalized'].map(energy_charge_map)\n",
    "consumption_df['fixed_charge'] = consumption_df['Category_normalized'].map(fixed_charge_map)\n",
    "\n",
    "\n",
    "# Step 3: Map elasticity values\n",
    "consumption_df['elasticity'] = consumption_df['Category_normalized'].map(elasticity_estimate_map)\n",
    "\n",
    "# Optional: Drop the helper column if not needed\n",
    "consumption_df.drop(columns=['Category_normalized'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "consumption_df['fixed_bill'] = consumption_df['fixed_charge']*consumption_df['Sanctioned_Load_KW']\n",
    "\n",
    "consumption_df['energy_bill'] = consumption_df['energy_charge']*consumption_df['monthly_consumption']\n",
    "\n",
    "\n",
    "# Ensure merged_ranges is a list of lists\n",
    "flattened_ranges = []\n",
    "for r in merged_ranges:\n",
    "    flattened_ranges.append(list(r))  # force range objects to list\n",
    "\n",
    "for period_index in range(len(flattened_ranges)):\n",
    "    for hour in flattened_ranges[period_index]:\n",
    "        original_col = f\"Consumption_Hr_{hour}\"\n",
    "        modified_col = f\"modified_Consumption_Hr_{hour}\"\n",
    "        period_col = f\"Period_{period_index}\"\n",
    "\n",
    "        # Multiply the original demand by the period factor using row-wise alignment\n",
    "        consumption_df[modified_col] = (\n",
    "            consumption_df[original_col] - ( (consumption_df['elasticity']*consumption_df[original_col]*(consumption_df[period_col] - consumption_df['energy_charge']) )/consumption_df['energy_charge'] )\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "# Loop through each period and its range\n",
    "for period_index in range(len(flattened_ranges)):\n",
    "    for hour in flattened_ranges[period_index]:\n",
    "        original_col = f\"Consumption_Hr_{hour}\"\n",
    "        modified_tou_cost_col = f\"modified_cost_Consumption_Hr_{hour}\"\n",
    "        modified_tou_col = f\"modified_Consumption_Hr_{hour}\"\n",
    "        period_col = f\"Period_{period_index}\"\n",
    "\n",
    "        # Multiply the original demand by the period factor using row-wise alignment\n",
    "        consumption_df[modified_tou_cost_col] = (\n",
    "            # modified_energy_tariff*modified_energy_demand\n",
    "            consumption_df[period_col]*consumption_df[modified_tou_col]\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for period_index in range(len(flattened_ranges)):\n",
    "    for hour in flattened_ranges[period_index]:\n",
    "        previous_tariff_col = f\"Existing_tariff_{hour}\"\n",
    "        modified_tariff_col = f\"Optimized_tariff_{hour}\"\n",
    "        period_col = f\"Period_{period_index}\"\n",
    "\n",
    "        # Multiply the original demand by the period factor using row-wise alignment\n",
    "        consumption_df[modified_tariff_col] = (\n",
    "            # modified_energy_tariff*modified_energy_demand\n",
    "            consumption_df[period_col]\n",
    "        )\n",
    "\n",
    "        consumption_df[previous_tariff_col] = (\n",
    "            # modified_energy_tariff*modified_energy_demand\n",
    "            consumption_df['energy_charge']\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "optimized_tariff_cols= [f\"Optimized_tariff_{hour+1}\" for hour in range(R)]\n",
    "existing_tariff_cols= [f\"Existing_tariff_{hour+1}\" for hour in range(R)]\n",
    "\n",
    "optimized_tariff_df = consumption_df.groupby(\"Consumer No\")[optimized_tariff_cols].mean().reset_index().round(2)\n",
    "existing_tariff_df = consumption_df.groupby(\"Consumer No\")[existing_tariff_cols].mean().reset_index().round(2)\n",
    "\n",
    "# Step 4: Add 'Type' column\n",
    "optimized_tariff_df['Type'] = 'After Optimization'\n",
    "existing_tariff_df['Type'] = 'Before Optimization'\n",
    "\n",
    "# Step 1: Define new column names\n",
    "renamed_tariff_cols = {f\"Optimized_tariff_{hour+1}\": f\"Tariff_{hour+1}\" for hour in range(R)}\n",
    "renamed_tariff_cols_existing = {f\"Existing_tariff_{hour+1}\": f\"Tariff_{hour+1}\" for hour in range(R)}\n",
    "\n",
    "# Step 2: Rename the columns in both dataframes\n",
    "optimized_tariff_df = optimized_tariff_df.rename(columns=renamed_tariff_cols)\n",
    "existing_tariff_df = existing_tariff_df.rename(columns=renamed_tariff_cols_existing)\n",
    "\n",
    "# Step 6: Combine both DataFrames\n",
    "combined_tariff_df = pd.concat([optimized_tariff_df, existing_tariff_df], ignore_index=True)\n",
    "\n",
    "\n",
    "# Step 1: Identify original and modified hourly columns\n",
    "consumption_cols = [col for col in consumption_df.columns if col.startswith(\"Consumption_Hr_\")]\n",
    "modified_cols = [col for col in consumption_df.columns if col.startswith(\"modified_Consumption_Hr_\")]\n",
    "\n",
    "# Step 2: Group by Consumer No and compute mean\n",
    "mean_consumption = consumption_df.groupby(\"Consumer No\")[consumption_cols].mean()\n",
    "mean_modified = consumption_df.groupby(\"Consumer No\")[modified_cols].mean()\n",
    "\n",
    "# Step 3: Rename columns to unified 'Hour_X' format\n",
    "mean_consumption.columns = [f\"Hour_{col.split('_')[-1]}\" for col in mean_consumption.columns]\n",
    "mean_modified.columns = [f\"Hour_{col.split('_')[-1]}\" for col in mean_modified.columns]\n",
    "\n",
    "# Step 4: Add 'Type' column\n",
    "mean_consumption['Type'] = 'Before Optimization'\n",
    "mean_modified['Type'] = 'After Optimization'\n",
    "\n",
    "# Step 5: Reset index to bring 'Consumer No' back as a column\n",
    "mean_consumption = mean_consumption.reset_index()\n",
    "mean_modified = mean_modified.reset_index()\n",
    "\n",
    "# Step 6: Combine both DataFrames\n",
    "combined_df = pd.concat([mean_consumption, mean_modified], ignore_index=True)\n",
    "\n",
    "# Step 7: Reorder columns to match the desired format\n",
    "hour_cols = sorted([col for col in combined_df.columns if col.startswith(\"Hour_\")], key=lambda x: int(x.split('_')[1]))\n",
    "combined_df = combined_df[['Consumer No', 'Type'] + hour_cols]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Convert \"Date\" column to datetime if it's not already\n",
    "consumption_df[\"Date\"] = pd.to_datetime(consumption_df[\"Date\"])\n",
    "\n",
    "# 2. Create the \"Month\" column in YYYY-MM format or just Month number\n",
    "#consumption_df[\"Month\"] = consumption_df[\"Date\"].dt.to_period(\"M\").astype(str)  # e.g., \"2025-05\"\n",
    "consumption_df[\"Month\"] = consumption_df[\"Date\"].dt.strftime(\"%B\")\n",
    "\n",
    "# Or use .dt.month for just month number: dt.month\n",
    "\n",
    "# 3. Create a Consumer No to Month mapping (e.g., latest month per consumer)\n",
    "consumer_month_map = consumption_df.groupby(\"Consumer No\")[\"Month\"].first().to_dict()\n",
    "# You can use .last() or a more custom rule if needed\n",
    "\n",
    "# 4. Map to other dataframes\n",
    "combined_df[\"Month\"] = consumption_df[\"Consumer No\"].map(consumer_month_map)\n",
    "combined_tariff_df[\"Month\"] = consumption_df[\"Consumer No\"].map(consumer_month_map)\n",
    "\n",
    "\n",
    "columns_to_sum = [f\"modified_cost_Consumption_Hr_{t+1}\" for t in range(R)]\n",
    "new_bill = consumption_df.groupby(\"Consumer No\")[columns_to_sum].sum()\n",
    "new_bill[\"Optimized_Energy_bill\"] = new_bill.sum(axis=1)\n",
    "new_bill = new_bill[[\"Optimized_Energy_bill\"]].reset_index()\n",
    "\n",
    "# 3. Create a Consumer No to Month mapping (e.g., latest month per consumer)\n",
    "new_bill_map = new_bill.groupby(\"Consumer No\")[\"Optimized_Energy_bill\"].first().to_dict()\n",
    "\n",
    "# 4. Map to other dataframes\n",
    "combined_df[\"Optimized_Energy_bill\"] = combined_df[\"Consumer No\"].map(new_bill_map)\n",
    "consumption_df[\"Optimized_Energy_bill\"] = consumption_df[\"Consumer No\"].map(new_bill_map)\n",
    "\n",
    "consumption_df['net_savings'] = - consumption_df['Optimized_Energy_bill'] + consumption_df['energy_bill']\n",
    "consumption_df['change_in_bill'] = consumption_df['Optimized_Energy_bill'] - consumption_df['energy_bill']\n",
    "\n",
    "consumption_df['net_savings%'] = (( (consumption_df['net_savings'] )/ consumption_df['energy_bill'] )*100 ).round(2)\n",
    "\n",
    "# 3. Create a Consumer No to Month mapping (e.g., latest month per consumer)\n",
    "consumer_savings_map = consumption_df.groupby(\"Consumer No\")[\"net_savings\"].first().to_dict()\n",
    "consumer_savings_percent_map = consumption_df.groupby(\"Consumer No\")[\"net_savings%\"].first().to_dict()\n",
    "consumer_original_bill_map = consumption_df.groupby(\"Consumer No\")[\"energy_bill\"].first().to_dict()\n",
    "consumer_sanctioned_load_map = consumption_df.groupby(\"Consumer No\")[\"Sanctioned_Load_KW\"].first().to_dict()\n",
    "consumer_monthly_demand_map = consumption_df.groupby(\"Consumer No\")[\"monthly_consumption\"].first().to_dict()\n",
    "\n",
    "\n",
    "# 4. Map to other dataframes\n",
    "combined_df[\"net_savings\"] = consumption_df[\"Consumer No\"].map(consumer_savings_map)\n",
    "# 4. Map to other dataframes\n",
    "combined_df[\"net_savings%\"] = consumption_df[\"Consumer No\"].map(consumer_savings_percent_map)\n",
    "combined_df[\"Energy_bill_with_existing_tariffs\"] = consumption_df[\"Consumer No\"].map(consumer_original_bill_map)\n",
    "combined_df[\"monthly_consumption\"] = consumption_df[\"Consumer No\"].map(consumer_monthly_demand_map)\n",
    "combined_df[\"Sanctioned_Load_KW\"] = consumption_df[\"Consumer No\"].map(consumer_sanctioned_load_map)\n",
    "\n",
    "required_columns = ['Consumer No', 'Type', 'Hour_1', 'Hour_2', 'Hour_3', 'Hour_4', 'Hour_5',\n",
    "        'Hour_6', 'Hour_7', 'Hour_8', 'Hour_9', 'Hour_10', 'Hour_11', 'Hour_12',\n",
    "        'Hour_13', 'Hour_14', 'Hour_15', 'Hour_16', 'Hour_17', 'Hour_18',\n",
    "        'Hour_19', 'Hour_20', 'Hour_21', 'Hour_22', 'Hour_23', 'Hour_24',\n",
    "        'Month', 'Optimized_Energy_bill', 'net_savings', 'net_savings%',\n",
    "        'Energy_bill_with_existing_tariffs', 'monthly_consumption',\n",
    "        'Sanctioned_Load_KW']\n",
    "\n",
    "bills_df = combined_df[[ \"Month\", \"Consumer No\", *required_columns,]].round(2)\n",
    "\n",
    "if ( 'Optimized_Energy_bill' in consumption_df.columns )== False:\n",
    "    consumption_df = consumption_df.merge(new_bill, on=\"Consumer No\", how=\"left\")\n",
    "\n",
    "\n",
    "combined_df[\"Sanctioned_Load_KW\"] = combined_df[\"Consumer No\"].map(consumer_sanctioned_load_map)\n",
    "combined_df[\"net_savings\"] = combined_df[\"Consumer No\"].map(consumer_savings_map)\n",
    "combined_df[\"net_savings%\"] = combined_df[\"Consumer No\"].map(consumer_savings_percent_map)\n",
    "combined_df[\"Month\"] = combined_df[\"Consumer No\"].map(consumer_month_map)\n",
    "combined_df[\"monthly_consumption\"] = combined_df[\"Consumer No\"].map(consumer_monthly_demand_map)\n",
    "\n",
    "required_columns = combined_df.columns\n",
    "\n",
    "combined_demand_df = combined_df\n",
    "\n",
    "# Move \"Month\" to be the first column\n",
    "cols = ['Sanctioned_Load_KW'] + ['net_savings']  + ['net_savings%'] + ['monthly_consumption'] + ['Month']  + ['Consumer No'] + ['Type'] + hour_cols\n",
    "\n",
    "combined_demand_df = combined_demand_df[cols].round(2)\n",
    "\n",
    "\n",
    "# Create a mapping from Consumer No to Change_in_Profit\n",
    "change_in_profit_map = df_change_in_profit.set_index(\"Consumer_No\")[\"Change_in_Profit\"].to_dict()\n",
    "\n",
    "# Example usage: map to combined_df (if needed)\n",
    "combined_demand_df[\"Change_in_Retailer_Profit\"] = combined_demand_df[\"Consumer No\"].map(change_in_profit_map)\n",
    "\n",
    "# import datetime as dt\n",
    "\n",
    "\n",
    "# date_time_string = dt.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "# print(date_time_string)\n",
    "\n",
    "#output_file_name = f\"{output_folder}/output_file_{date_time_string}.xlsx\"\n",
    "#output_file_name = f\"{output_folder}/output_file.xlsx\"\n",
    "\n",
    "\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "\n",
    "consumption_cols = [f\"Consumption_Hr_{hour}\" for hour in range(1,25)]\n",
    "\n",
    "mean_consumption = df.groupby(\"Consumer No\")[consumption_cols].mean().reset_index()\n",
    "\n",
    "consumer_demand_rep_df = mean_consumption\n",
    "\n",
    "if 'Meter No' not in consumer_demand_rep_df.columns:\n",
    "    consumer_demand_rep_df = consumer_demand_rep_df.merge(\n",
    "        df[['Consumer No', 'Meter No', 'Sanctioned_Load_KW', 'MeterPhase_Name', 'Category']].drop_duplicates(),\n",
    "        on = 'Consumer No',\n",
    "        how = \"left\"\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "if \"Period_0\" not in consumer_demand_rep_df.columns:\n",
    "\n",
    "    consumer_demand_rep_df['Consumer No'] = consumer_demand_rep_df['Consumer No'].astype(str).replace(\" \", \"\")\n",
    "\n",
    "    consumer_demand_rep_df = consumer_demand_rep_df.merge(\n",
    "        modified_lambda_df[[\"Consumer No\"] + [f\"Period_{i}\" for i in range(T)]],\n",
    "        on=\"Consumer No\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "\n",
    "consumption_rep_df = consumer_demand_rep_df\n",
    "\n",
    "# Step 1: Normalize the Category column in consumption_rep_df\n",
    "consumption_rep_df['Category_normalized'] = (\n",
    "    consumption_rep_df['Category'].str.lower().str.replace(\" \", \"\", regex=False)\n",
    ")\n",
    "\n",
    "\n",
    "# Merge on \"Consumer No\" to bring Period_1 to Period_T columns\n",
    "\n",
    "# Step 1: Normalize Category in lambda_C_assam\n",
    "lambda_C_assam['Category_normalized'] = (\n",
    "    lambda_C_assam['Category'].str.lower().str.replace(\" \", \"\", regex=False)\n",
    ")\n",
    "\n",
    "# Step 2: Create the maps\n",
    "energy_charge_rep_map = dict(\n",
    "    zip(lambda_C_assam['Category_normalized'], lambda_C_assam['energy_charges'])\n",
    ")\n",
    "\n",
    "fixed_charge_rep_map = dict(\n",
    "    zip(lambda_C_assam['Category_normalized'], lambda_C_assam['Revised_Fixed_Charges'])\n",
    ")\n",
    "\n",
    "\n",
    "# Apply maps\n",
    "consumption_rep_df['energy_charge'] = consumption_rep_df['Category_normalized'].map(energy_charge_rep_map)\n",
    "consumption_rep_df['fixed_charge'] = consumption_rep_df['Category_normalized'].map(fixed_charge_rep_map)\n",
    "\n",
    "\n",
    "# Step 3: Map elasticity values\n",
    "consumption_rep_df['elasticity'] = consumption_rep_df['Category_normalized'].map(elasticity_estimate_map)\n",
    "\n",
    "# Optional: Drop the helper column if not needed\n",
    "consumption_rep_df.drop(columns=['Category_normalized'], inplace=True)\n",
    "\n",
    "consumption_rep_df['fixed_bill'] = consumption_rep_df['fixed_charge']*consumption_rep_df['Sanctioned_Load_KW']\n",
    "#consumption_rep_df['energy_bill'] = consumption_rep_df['energy_charge']*consumption_rep_df['monthly_consumption']\n",
    "\n",
    "\n",
    "# Ensure merged_ranges is a list of lists\n",
    "flattened_ranges = []\n",
    "for r in merged_ranges:\n",
    "    flattened_ranges.append(list(r))  # force range objects to list\n",
    "\n",
    "\n",
    "for period_index in range(len(flattened_ranges)):\n",
    "    for hour in flattened_ranges[period_index]:\n",
    "        original_col = f\"Consumption_Hr_{hour}\"\n",
    "        modified_col = f\"original_cost_Consumption_Hr_{hour}\"\n",
    "        period_col = f\"Period_{period_index}\"\n",
    "\n",
    "        # Multiply the original demand by the period factor using row-wise alignment\n",
    "        consumption_rep_df[modified_col] = (\n",
    "            consumption_rep_df[original_col]*consumption_rep_df['energy_charge']\n",
    "        )\n",
    "\n",
    "columns_to_sum = [f\"original_cost_Consumption_Hr_{t+1}\" for t in range(R)]\n",
    "old_bill = consumption_rep_df.groupby(\"Consumer No\")[columns_to_sum].sum()\n",
    "old_bill[\"energy_bill\"] = old_bill.sum(axis=1)\n",
    "old_bill = old_bill[[\"energy_bill\"]].reset_index()\n",
    "\n",
    "\n",
    "# Ensure merged_ranges is a list of lists\n",
    "flattened_ranges = []\n",
    "for r in merged_ranges:\n",
    "    flattened_ranges.append(list(r))  # force range objects to list\n",
    "\n",
    "for period_index in range(len(flattened_ranges)):\n",
    "    for hour in flattened_ranges[period_index]:\n",
    "        original_col = f\"Consumption_Hr_{hour}\"\n",
    "        modified_col = f\"modified_Consumption_Hr_{hour}\"\n",
    "        period_col = f\"Period_{period_index}\"\n",
    "\n",
    "        # Multiply the original demand by the period factor using row-wise alignment\n",
    "        consumption_rep_df[modified_col] = (\n",
    "            consumption_rep_df[original_col] - ( (consumption_rep_df['elasticity']*consumption_rep_df[original_col]*(consumption_rep_df[period_col] - consumption_rep_df['energy_charge']) )/consumption_rep_df['energy_charge'] )\n",
    "        )\n",
    "\n",
    "\n",
    "# Loop through each period and its range\n",
    "for period_index in range(len(flattened_ranges)):\n",
    "    for hour in flattened_ranges[period_index]:\n",
    "        original_col = f\"Consumption_Hr_{hour}\"\n",
    "        modified_tou_cost_col = f\"modified_cost_Consumption_Hr_{hour}\"\n",
    "        modified_tou_col = f\"modified_Consumption_Hr_{hour}\"\n",
    "        period_col = f\"Period_{period_index}\"\n",
    "\n",
    "        # Multiply the original demand by the period factor using row-wise alignment\n",
    "        consumption_rep_df[modified_tou_cost_col] = (\n",
    "            # modified_energy_tariff*modified_energy_demand\n",
    "            consumption_rep_df[period_col]*consumption_rep_df[modified_tou_col]\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for period_index in range(len(flattened_ranges)):\n",
    "    for hour in flattened_ranges[period_index]:\n",
    "        previous_tariff_col = f\"Existing_tariff_{hour}\"\n",
    "        modified_tariff_col = f\"Optimized_tariff_{hour}\"\n",
    "        period_col = f\"Period_{period_index}\"\n",
    "\n",
    "        # Multiply the original demand by the period factor using row-wise alignment\n",
    "        consumption_rep_df[modified_tariff_col] = (\n",
    "            # modified_energy_tariff*modified_energy_demand\n",
    "            consumption_rep_df[period_col]\n",
    "        )\n",
    "\n",
    "        consumption_rep_df[previous_tariff_col] = (\n",
    "            # modified_energy_tariff*modified_energy_demand\n",
    "            consumption_rep_df['energy_charge']\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "optimized_tariff_cols= [f\"Optimized_tariff_{hour+1}\" for hour in range(R)]\n",
    "existing_tariff_cols= [f\"Existing_tariff_{hour+1}\" for hour in range(R)]\n",
    "\n",
    "optimized_tariff_rep_df = consumption_rep_df.groupby(\"Consumer No\")[optimized_tariff_cols].mean().reset_index().round(2)\n",
    "existing_tariff_rep_df = consumption_rep_df.groupby(\"Consumer No\")[existing_tariff_cols].mean().reset_index().round(2)\n",
    "\n",
    "# Step 4: Add 'Type' column\n",
    "optimized_tariff_rep_df['Type'] = 'After Optimization'\n",
    "existing_tariff_rep_df['Type'] = 'Before Optimization'\n",
    "\n",
    "# Step 1: Define new column names\n",
    "renamed_tariff_cols = {f\"Optimized_tariff_{hour+1}\": f\"Tariff_{hour+1}\" for hour in range(R)}\n",
    "renamed_tariff_cols_existing = {f\"Existing_tariff_{hour+1}\": f\"Tariff_{hour+1}\" for hour in range(R)}\n",
    "\n",
    "# Step 2: Rename the columns in both dataframes\n",
    "optimized_tariff_rep_df = optimized_tariff_rep_df.rename(columns=renamed_tariff_cols)\n",
    "existing_tariff_rep_df = existing_tariff_rep_df.rename(columns=renamed_tariff_cols_existing)\n",
    "\n",
    "# Step 6: Combine both DataFrames\n",
    "combined_tariff_rep_df = pd.concat([optimized_tariff_rep_df, existing_tariff_rep_df], ignore_index=True)\n",
    "\n",
    "\n",
    "# Step 1: Identify original and modified hourly columns\n",
    "consumption_cols = [col for col in consumption_rep_df.columns if col.startswith(\"Consumption_Hr_\")]\n",
    "modified_cols = [col for col in consumption_rep_df.columns if col.startswith(\"modified_Consumption_Hr_\")]\n",
    "\n",
    "# Step 2: Group by Consumer No and compute mean\n",
    "mean_consumption = consumption_rep_df.groupby(\"Consumer No\")[consumption_cols].mean()\n",
    "mean_modified = consumption_rep_df.groupby(\"Consumer No\")[modified_cols].mean()\n",
    "\n",
    "# Step 3: Rename columns to unified 'Hour_X' format\n",
    "mean_consumption.columns = [f\"Hour_{col.split('_')[-1]}\" for col in mean_consumption.columns]\n",
    "mean_modified.columns = [f\"Hour_{col.split('_')[-1]}\" for col in mean_modified.columns]\n",
    "\n",
    "# Step 4: Add 'Type' column\n",
    "mean_consumption['Type'] = 'Before Optimization'\n",
    "mean_modified['Type'] = 'After Optimization'\n",
    "\n",
    "# Step 5: Reset index to bring 'Consumer No' back as a column\n",
    "mean_consumption = mean_consumption.reset_index()\n",
    "mean_modified = mean_modified.reset_index()\n",
    "\n",
    "# Step 6: Combine both DataFrames\n",
    "combined_rep_df = pd.concat([mean_consumption, mean_modified], ignore_index=True)\n",
    "\n",
    "# Step 7: Reorder columns to match the desired format\n",
    "hour_cols = sorted([col for col in combined_rep_df.columns if col.startswith(\"Hour_\")], key=lambda x: int(x.split('_')[1]))\n",
    "combined_rep_df = combined_rep_df[['Consumer No', 'Type'] + hour_cols]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Convert \"Date\" column to datetime if it's not already\n",
    "#consumption_rep_df[\"Date\"] = pd.to_datetime(consumption_rep_df[\"Date\"])\n",
    "\n",
    "# 2. Create the \"Month\" column in YYYY-MM format or just Month number\n",
    "#consumption_rep_df[\"Month\"] = consumption_rep_df[\"Date\"].dt.to_period(\"M\").astype(str)  # e.g., \"2025-05\"\n",
    "#consumption_rep_df[\"Month\"] = consumption_rep_df[\"Date\"].dt.strftime(\"%B\")\n",
    "\n",
    "# Or use .dt.month for just month number: dt.month\n",
    "\n",
    "# 3. Create a Consumer No to Month mapping (e.g., latest month per consumer)\n",
    "#consumer_month_rep_map = consumption_rep_df.groupby(\"Consumer No\")[\"Month\"].first().to_dict()\n",
    "# You can use .last() or a more custom rule if needed\n",
    "\n",
    "# 4. Map to other dataframes\n",
    "#combined_rep_df[\"Month\"] = consumption_rep_df[\"Consumer No\"].map(consumer_month_rep_map)\n",
    "#combined_tariff_rep_df[\"Month\"] = consumption_rep_df[\"Consumer No\"].map(consumer_month_rep_map)\n",
    "\n",
    "\n",
    "columns_to_sum = [f\"modified_cost_Consumption_Hr_{t+1}\" for t in range(R)]\n",
    "new_bill = consumption_rep_df.groupby(\"Consumer No\")[columns_to_sum].sum()\n",
    "new_bill[\"Optimized_Energy_bill\"] = new_bill.sum(axis=1)\n",
    "new_bill = new_bill[[\"Optimized_Energy_bill\"]].reset_index()\n",
    "\n",
    "# 3. Create a Consumer No to Month mapping (e.g., latest month per consumer)\n",
    "new_bill_rep_map = new_bill.groupby(\"Consumer No\")[\"Optimized_Energy_bill\"].first().to_dict()\n",
    "\n",
    "# 4. Map to other dataframes\n",
    "combined_rep_df[\"Optimized_Energy_bill\"] = combined_rep_df[\"Consumer No\"].map(new_bill_rep_map)\n",
    "consumption_rep_df[\"Optimized_Energy_bill\"] = consumption_rep_df[\"Consumer No\"].map(new_bill_rep_map)\n",
    "\n",
    "\n",
    "# 3. Create a Consumer No to Month mapping (e.g., latest month per consumer)\n",
    "old_bill_rep_map = old_bill.groupby(\"Consumer No\")[\"energy_bill\"].first().to_dict()\n",
    "\n",
    "# 4. Map to other dataframes\n",
    "combined_rep_df[\"energy_bill\"] = combined_rep_df[\"Consumer No\"].map(old_bill_rep_map)\n",
    "consumption_rep_df[\"energy_bill\"] = consumption_rep_df[\"Consumer No\"].map(old_bill_rep_map)\n",
    "\n",
    "\n",
    "\n",
    "consumption_rep_df['net_savings'] = ( - consumption_rep_df['Optimized_Energy_bill'] + consumption_rep_df['energy_bill'])*30\n",
    "consumption_rep_df['change_in_bill'] = (consumption_rep_df['Optimized_Energy_bill'] - consumption_rep_df['energy_bill'])*30\n",
    "\n",
    "consumption_rep_df['net_savings%'] = (( (consumption_rep_df['net_savings'] )/ consumption_rep_df['energy_bill'] )*100 ).round(2)\n",
    "\n",
    "# 3. Create a Consumer No to Month mapping (e.g., latest month per consumer)\n",
    "consumer_savings_rep_map = consumption_rep_df.groupby(\"Consumer No\")[\"net_savings\"].first().to_dict()\n",
    "consumer_savings_percent_rep_map = consumption_rep_df.groupby(\"Consumer No\")[\"net_savings%\"].first().to_dict()\n",
    "consumer_original_bill_rep_map = consumption_rep_df.groupby(\"Consumer No\")[\"energy_bill\"].first().to_dict()\n",
    "consumer_sanctioned_load_rep_map = consumption_rep_df.groupby(\"Consumer No\")[\"Sanctioned_Load_KW\"].first().to_dict()\n",
    "#consumer_monthly_demand_rep_map = consumption_rep_df.groupby(\"Consumer No\")[\"monthly_consumption\"].first().to_dict()\n",
    "\n",
    "\n",
    "# 4. Map to other dataframes\n",
    "combined_rep_df[\"net_savings\"] = combined_rep_df[\"Consumer No\"].map(consumer_savings_rep_map)\n",
    "# 4. Map to other dataframes\n",
    "combined_rep_df[\"net_savings%\"] = combined_rep_df[\"Consumer No\"].map(consumer_savings_percent_rep_map)\n",
    "combined_rep_df[\"Energy_bill_with_existing_tariffs\"] = combined_rep_df[\"Consumer No\"].map(consumer_original_bill_rep_map)\n",
    "#combined_rep_df[\"monthly_consumption\"] = consumption_rep_df[\"Consumer No\"].map(consumer_monthly_demand_rep_map)\n",
    "combined_rep_df[\"Sanctioned_Load_KW\"] = combined_rep_df[\"Consumer No\"].map(consumer_sanctioned_load_rep_map)\n",
    "\n",
    "required_columns = ['Consumer No', 'Type', 'Hour_1', 'Hour_2', 'Hour_3', 'Hour_4', 'Hour_5',\n",
    "        'Hour_6', 'Hour_7', 'Hour_8', 'Hour_9', 'Hour_10', 'Hour_11', 'Hour_12',\n",
    "        'Hour_13', 'Hour_14', 'Hour_15', 'Hour_16', 'Hour_17', 'Hour_18',\n",
    "        'Hour_19', 'Hour_20', 'Hour_21', 'Hour_22', 'Hour_23', 'Hour_24',\n",
    "        #'Month', \n",
    "        'Optimized_Energy_bill', 'net_savings', 'net_savings%',\n",
    "        'Energy_bill_with_existing_tariffs', \n",
    "        #'monthly_consumption',\n",
    "        'Sanctioned_Load_KW']\n",
    "\n",
    "#bills_rep_df = combined_rep_df[[ \"Month\", \"Consumer No\", *required_columns,]].round(2)\n",
    "\n",
    "bills_rep_df = combined_rep_df[[ \"Consumer No\", *required_columns,]].round(2)\n",
    "\n",
    "\n",
    "if ( 'Optimized_Energy_bill' in consumption_rep_df.columns )== False:\n",
    "    consumption_rep_df = consumption_rep_df.merge(new_bill, on=\"Consumer No\", how=\"left\")\n",
    "\n",
    "\n",
    "combined_rep_df[\"Sanctioned_Load_KW\"] = combined_rep_df[\"Consumer No\"].map(consumer_sanctioned_load_rep_map)\n",
    "combined_rep_df[\"net_savings\"] = combined_rep_df[\"Consumer No\"].map(consumer_savings_rep_map)\n",
    "combined_rep_df[\"net_savings%\"] = combined_rep_df[\"Consumer No\"].map(consumer_savings_percent_rep_map)\n",
    "#combined_rep_df[\"Month\"] = combined_rep_df[\"Consumer No\"].map(consumer_month_rep_map)\n",
    "#combined_rep_df[\"monthly_consumption\"] = combined_rep_df[\"Consumer No\"].map(consumer_monthly_demand_rep_map)\n",
    "\n",
    "required_columns = combined_rep_df.columns\n",
    "\n",
    "combined_demand_rep_df = combined_rep_df\n",
    "\n",
    "# Move \"Month\" to be the first column\n",
    "#cols = ['Sanctioned_Load_KW'] + ['net_savings']  + ['net_savings%'] + ['monthly_consumption'] + ['Month']  + ['Consumer No'] + ['Type'] + hour_cols\n",
    "\n",
    "cols = ['Sanctioned_Load_KW'] + ['net_savings']  + ['net_savings%']   + ['Consumer No'] + ['Type'] + hour_cols\n",
    "\n",
    "\n",
    "combined_demand_rep_df = combined_demand_rep_df[cols].round(2)\n",
    "\n",
    "\n",
    "# Create a mapping from Consumer No to Change_in_Profit\n",
    "change_in_profit_rep_map = df_change_in_profit.set_index(\"Consumer_No\")[\"Change_in_Profit\"].to_dict()\n",
    "\n",
    "# Example usage: map to combined_rep_df (if needed)\n",
    "combined_demand_rep_df[\"Change_in_Retailer_Profit\"] = combined_demand_rep_df[\"Consumer No\"].map(change_in_profit_rep_map)\n",
    "\n",
    "# import datetime as dt\n",
    "\n",
    "\n",
    "# date_time_string = dt.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "# print(date_time_string)\n",
    "\n",
    "#output_file_name = f\"{output_folder}/output_file_{date_time_string}.xlsx\"\n",
    "#output_file_name = f\"{output_folder}/output_file.xlsx\"\n",
    "\n",
    "#print(f\"Total Retailer's Expected Profit Increase: INR {df_change_in_profit.loc['TOTAL']}\")\n",
    "\n",
    "# Write both dataframes into separate sheets\n",
    "# with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "#     #modified_lambda_rep_df.round(2).to_excel(writer, sheet_name=\"optimized_tariffs\", index=False)\n",
    "#     #delta_lambda_rep_df.round(2).to_excel(writer, sheet_name=\"change_in_tariffs\", index=False)\n",
    "#     #combined_demand_rep_df.round(2).to_excel(writer, sheet_name=\"updated_profile_average\", index=False)\n",
    "#     #combined_tariff_rep_df.round(2).to_excel(writer, sheet_name=\"updated_tariff\", index=False)\n",
    "#     bills_rep_df.to_excel(writer, sheet_name=\"bills_baseline_df\", index=False)\n",
    "#     consumption_rep_df.to_excel(writer, sheet_name=\"all_processing_rep_df\", index=False)\n",
    "#     #df_change_in_profit.to_excel(writer, sheet_name=\"retailers_increase_in_profit\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "#print(f\"Total Retailer's Expected Profit Increase: INR {df_change_in_profit.loc['TOTAL']}\")\n",
    "\n",
    "# Write both dataframes into separate sheets\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "    modified_lambda_df.round(2).to_excel(writer, sheet_name=\"optimized_tariffs\", index=False)\n",
    "    delta_lambda_df.round(2).to_excel(writer, sheet_name=\"change_in_tariffs\", index=False)\n",
    "    combined_demand_df.round(2).to_excel(writer, sheet_name=\"updated_profile_average\", index=False)\n",
    "    combined_tariff_df.round(2).to_excel(writer, sheet_name=\"updated_tariff\", index=False)\n",
    "    bills_df.to_excel(writer, sheet_name=\"bills_df\", index=False)\n",
    "    consumption_df.to_excel(writer, sheet_name=\"all_processing_df\", index=False)\n",
    "    bills_rep_df.to_excel(writer, sheet_name=\"bills_baseline_df\", index=False)\n",
    "    consumption_rep_df.to_excel(writer, sheet_name=\"all_processing_baseline_df\", index=False)\n",
    "    df_change_in_profit.to_excel(writer, sheet_name=\"retailers_increase_in_profit\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "###########################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
